{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85e2d1b3-eba3-4c9b-9573-f5cc162c5616",
   "metadata": {},
   "source": [
    "# Megaline Phone Plan Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc10ee40-abf5-4ffe-8ca4-0ceb387d5007",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71989d0-1e51-47a1-870b-e03a7860edc8",
   "metadata": {},
   "source": [
    "This project proceeds from an earlier project I completed (Sprint 3) where I processed the call/text/internet data for Megaline phone plan customers and ran statistical analysis to determine the most lucrative phone plans. This time, I am using this data to offer recommendations to customers for a new phone plan based off of their calls/texts/internet data. \n",
    "\n",
    "There are two possible plans. I will try out decision tree classification, random forest classification, and logistic regression models for this goal, and use a simple measure of accuracy to select the best-performing model for this problem. An accuracy of at least 0.75 will be needed, for Megaline to be able to offer robust recommendations. I will tweak the hyperparamters of these models to obtain the best performance.\n",
    "\n",
    "I am going to split the data into a training set, a validation set, and a test set up front and use the same sets throughout this project. I can use the validation set while I tweak hyperparameters, checking accuracy for each iteration, and then use the test set once at the very end of the evaluation to test the final model's performance. Then, I'll train the highest-performing model with the highest-performing hyperparameters on the entirety of the dataset to get an even better model. \n",
    "\n",
    "I will also perform a sanity check to ensure that the chosen model performs better than chance. To do this, I will determine the accuracy from guessing at random, and compare the model's accuracy to this. I want to make sure the model performs better than simple chance.\n",
    "\n",
    "Note - a plan number 1 indicates Ultra plan, whereas plan number 0 indicates Smart plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "978150b2-78c0-405e-a13b-6fd3d309816a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and models/functions\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# from sklearnex import patch_sklearn # Enhanced performance package for Intel processors\n",
    "# patch_sklearn()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee50051-cde4-4020-a496-ff39b536f695",
   "metadata": {
    "tags": []
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20e00ffc-354f-4cb3-9eca-81f5bdea8c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv('users_behavior.csv')\n",
    "except:\n",
    "    df = pd.read_csv('/datasets/users_behavior.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66454036-6d3c-44b9-83e3-5c008ad9776c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() # Look at dataset firsthand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67d63008-85f6-44d2-ba22-9c35ec056e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info() # Check for datatypes, dataset shape/size, any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a076530-1c53-4d6a-930e-2e456e0c4dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>63.038892</td>\n",
       "      <td>438.208787</td>\n",
       "      <td>38.281269</td>\n",
       "      <td>17207.673836</td>\n",
       "      <td>0.306472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>33.236368</td>\n",
       "      <td>234.569872</td>\n",
       "      <td>36.148326</td>\n",
       "      <td>7570.968246</td>\n",
       "      <td>0.461100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>274.575000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12491.902500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>430.600000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>16943.235000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>82.000000</td>\n",
       "      <td>571.927500</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>21424.700000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>244.000000</td>\n",
       "      <td>1632.060000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>49745.730000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             calls      minutes     messages       mb_used     is_ultra\n",
       "count  3214.000000  3214.000000  3214.000000   3214.000000  3214.000000\n",
       "mean     63.038892   438.208787    38.281269  17207.673836     0.306472\n",
       "std      33.236368   234.569872    36.148326   7570.968246     0.461100\n",
       "min       0.000000     0.000000     0.000000      0.000000     0.000000\n",
       "25%      40.000000   274.575000     9.000000  12491.902500     0.000000\n",
       "50%      62.000000   430.600000    30.000000  16943.235000     0.000000\n",
       "75%      82.000000   571.927500    57.000000  21424.700000     1.000000\n",
       "max     244.000000  1632.060000   224.000000  49745.730000     1.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all') # Make sure numbers are reasonable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02e8120-4e11-42ae-8868-ccb1c0a94998",
   "metadata": {},
   "source": [
    "It appears from the low (<0.5) mean and the median of 0.0 that the Smart plan is most common. Let's quantify how many users there are for each plan, just out of curiosity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b63081b1-252b-48b4-bf2d-4cf56ae56f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Ultra plan users: 985\n",
      "Percentage of users with Ultra plan: 0.30647168637212197\n"
     ]
    }
   ],
   "source": [
    "ultra_users = df.is_ultra.sum()\n",
    "print(\"Number of Ultra plan users:\", ultra_users)\n",
    "print(\"Percentage of users with Ultra plan:\", ultra_users / len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39672679-e301-434e-8803-f6a7be271202",
   "metadata": {},
   "source": [
    "So, out of ~3200 total users, a little under a third of them are Ultra plan users. The rest are Smart plan users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052e2e80-3dd8-42f0-8df7-9fc879babe3f",
   "metadata": {},
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb19e04-39d8-42bf-80cc-e012a00e9014",
   "metadata": {},
   "source": [
    "Now we will split the data into three different sets for training, validation, and testing, before employing a decision tree classification, a random forest classification, and a logistic regression classification model and ultimately choosing a top model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d445d097-c347-4e16-863e-b8da4eb20048",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8baf974-cd2d-49a7-92d2-83066b1d9942",
   "metadata": {},
   "source": [
    "Let's collect the features into one dataset by dropping the column with the target feature. And let's also collect the target feature into a series of its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46759511-7250-4f4b-9968-e21a49529436",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop('is_ultra', axis=1)\n",
    "target = df.is_ultra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c80d56-7b5d-460c-8bb4-3e5881333658",
   "metadata": {},
   "source": [
    "I want 60% of the data to be used for training, and 20% for the validation and test sets each. \n",
    "We will first split the features and target datasets into a training set and a test set, at an 80/20 ratio. \n",
    "Then, we can further divide this new training set into an ultimate training set and a validation set. In this case, the validation set needs to come from 25% of the training set to give us the 60/20/20 ratio. This is because 25% of 80 equals 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be979650-5477-4997-ace3-7bac5da992e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, features_test, y_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.2, random_state=123)\n",
    "\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    x_train, y_train, test_size=0.25, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b381db-6a8f-40ff-a3c1-81d2fb58ab8e",
   "metadata": {},
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b84e8a0-2543-45c4-b4c3-a8c5ad80320c",
   "metadata": {},
   "source": [
    "Let's first try out the decision tree. Its main hyperparameter is the maximum tree depth. Let's write a loop to try out a variety of tree depths and find the one with the highest accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45969409-8807-43e5-9539-8d822923dd60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.7947122861586314 obtained using max depth 9.\n"
     ]
    }
   ],
   "source": [
    "best_depth = 0\n",
    "best_score = 0\n",
    "model_tree = None\n",
    "\n",
    "for depth in range(1,11):\n",
    "    model = DecisionTreeClassifier(max_depth=depth, random_state = 123) # create instance of class\n",
    "    model.fit(features_train, target_train) # Fit model with training data\n",
    "    score = model.score(features_valid, target_valid) # Calculate accuracy\n",
    "    \n",
    "    # Document the highest-performing hyperparamaters, along with their corresponding accuracy\n",
    "    if score > best_score: \n",
    "        best_score = score\n",
    "        best_depth = depth\n",
    "        model_tree = model\n",
    "        \n",
    "print(f'Best accuracy: {best_score} obtained using max depth {best_depth}.') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ff870e-824d-4ca6-84f5-c50da63d24da",
   "metadata": {},
   "source": [
    "It looks like the simple decision tree has an accuracy of 79.5% when using the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c6eaa1-2fca-4045-bd07-7d85b8777f1d",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c5725b-86fd-49f1-85fd-4dcc4df2494c",
   "metadata": {},
   "source": [
    "The random forest model's main hyperparameters are maximum tree depth and the number of estimators. Let's iterate through both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcfa3ee0-d79b-42b0-9fd4-5e43b895c95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.7978227060653188 obtained using 40 trees with max_depth 6.\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_est = 0\n",
    "best_depth = 0\n",
    "model_forest = None\n",
    "\n",
    "for est in range (10, 81, 10):\n",
    "    for depth in range (1, 11):\n",
    "        model = RandomForestClassifier(\n",
    "            max_features=1.0, # The lack of this hyperparameter was causing warnings.\n",
    "            n_estimators=est, max_depth=depth, random_state=123)\n",
    "        model.fit(features_train, target_train)\n",
    "        score = model.score(features_valid, target_valid)\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_est = est\n",
    "            best_depth = depth\n",
    "            model_forest = model\n",
    "            \n",
    "print(f\"Best accuracy: {best_score} obtained using {best_est} trees with\\\n",
    " max_depth {best_depth}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8681b369-7e38-4095-907b-240753b9a843",
   "metadata": {},
   "source": [
    "Hmm, the accuracy on this model isn't that much better than it was on the decision tree, but it is better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d75a35f-000a-4f8c-8f2b-a13d47add810",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638730f6-e5e7-4e48-8731-ed17551c2c08",
   "metadata": {},
   "source": [
    "I don't see a reason to use both a validation and a testing set for logistic regression, because there are no hyperparameters to tune using an intermediate validation set. I don't want to under-utilize the dataset. I could resplit the original dataset into a 75/25 ratio, but I already have a 80/20 training/testing split from my original split that I can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8f0cdd2-1e86-43c6-9077-9585ea4b38ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.7142116182572614\n",
      "Validation accuracy: 0.702954898911353\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver='liblinear', random_state=123) # Using liblinear for small dataset\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "score_train = model.score(features_train, target_train)\n",
    "print(f'Training accuracy: {score_train}')\n",
    "\n",
    "score_valid = model.score(features_valid, target_valid)\n",
    "print(f'Validation accuracy: {score_valid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5e8a89-c886-4952-9691-2a4489cee8f1",
   "metadata": {},
   "source": [
    "This logistic regression model performs below both of the other models we tested, below above the cutoff of 75%. The lower validation accuracy also could indicate some overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d5c00c-dd3d-4fe6-b40d-d01fdaec03dd",
   "metadata": {},
   "source": [
    "## Top model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c0b6a0-6df3-4ff3-8047-76b962cb20cc",
   "metadata": {},
   "source": [
    "We found the top-performing model in terms of accuracy to be the random forest classifier, using 20 trees with a max depth of 7. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ffb110b-5130-4187-a64b-513cf1cb2301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.8133748055987559\n"
     ]
    }
   ],
   "source": [
    "score_test = model_forest.score(features_test, target_test)\n",
    "print(f'Testing accuracy: {score_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8365da4-de61-4068-896e-49b2afc3b4c2",
   "metadata": {},
   "source": [
    "The tested accuracy is 81.3%, and it has exceeded the validation set accuracy. It was slower to train than the other models, so for a larger dataset, this may become too large of a drawback - but it worked quickly enough for this small dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19c2d67-fe9e-483e-8643-520f81101477",
   "metadata": {},
   "source": [
    "Let's do a sanity check - there are two plan options, which implies a 50/50 split in users with each plan. In reality, it is approximately a 70/30 split (Smart/Ultra). The model should be performing with over 70% accuracy, as simply guessing \"Smart\" for each observation would yield approximately a 70% accuracy rate. So, our model performs better than chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e7dc0b6-0fbc-40fc-b056-ddcfd229223e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MegalinePlanRecommender.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model to a joblib file for sharing\n",
    "dump(model_forest, 'MegalinePlanRecommender.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a5e1e2-42cb-4f75-b463-5c523e464b5e",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e079dbe4-cf91-4ed8-8012-a0b57eb68519",
   "metadata": {},
   "source": [
    "I have attempted to offer recommendations to customers for a new phone plan (Ultra vs Smart) based off of their calls/texts/internet data, using supervised learning classifier models. I tried out a decision tree classifier, a random forest classifier, and a logistic regression classifer, and split my data 60/20/20 (training/validation/testing). The random model performed best in terms of accuracy, with a tested accuracy of 81.0%, though it was the slowest by far to train. For this small dataset, the training speed was very much adequate. I included code to save the model into a joblib file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
